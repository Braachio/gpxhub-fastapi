from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import JSONResponse
import pandas as pd
from typing import List, Dict, Optional
from datetime import datetime, timedelta

from utils.supabase_client import supabase
from utils.sanitize import sanitize_for_json
from services.lap_data import fetch_lap_meta_and_data
from services.fixed_sector import get_sector_summary_by_lap_id
from services.braking_dynamics import analyze_braking_dynamics
from services.track_corners import get_corner_segments_for_track

router = APIRouter()

@router.get("/dashboard/overview/{user_id}")
async def get_dashboard_overview(
    user_id: str,
    track: Optional[str] = Query(None, description="íŠ¹ì • íŠ¸ë™ í•„í„°ë§"),
    days: int = Query(30, description="ì¡°íšŒ ê¸°ê°„ (ì¼)")
):
    """
    ì‚¬ìš©ì ëŒ€ì‹œë³´ë“œ ê°œìš” ë°ì´í„° ì œê³µ
    - ìµœê·¼ ë© ìš”ì•½
    - ì„±ëŠ¥ íŠ¸ë Œë“œ
    - í•µì‹¬ ì§€í‘œ
    """
    try:
        # 1ï¸âƒ£ ìµœê·¼ ë© ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        date_filter = datetime.now() - timedelta(days=days)
        
        query = supabase.table("lap_meta").select("*").eq("user_id", user_id)
        if track:
            query = query.eq("track", track.lower())
        
        recent_laps = query.gte("created_at", date_filter.isoformat()).order("created_at", desc=True).limit(20).execute()
        
        if not recent_laps.data:
            return {
                "user_id": user_id,
                "track": track,
                "period_days": days,
                "total_laps": 0,
                "summary": {
                    "best_lap_time": None,
                    "average_lap_time": None,
                    "improvement_trend": None,
                    "total_distance": 0
                },
                "recent_laps": [],
                "performance_metrics": {},
                "track_leaderboard": []
            }

        # 2ï¸âƒ£ ê¸°ë³¸ í†µê³„ ê³„ì‚°
        lap_times = [lap["lap_time"] for lap in recent_laps.data if lap["lap_time"]]
        best_lap_time = min(lap_times) if lap_times else None
        avg_lap_time = sum(lap_times) / len(lap_times) if lap_times else None
        
        # 3ï¸âƒ£ ê°œì„  íŠ¸ë Œë“œ ê³„ì‚° (ìµœê·¼ 5ê°œ vs ì´ì „ 5ê°œ)
        improvement_trend = None
        if len(lap_times) >= 10:
            recent_5 = lap_times[:5]
            previous_5 = lap_times[5:10]
            recent_avg = sum(recent_5) / len(recent_5)
            previous_avg = sum(previous_5) / len(previous_5)
            improvement_trend = previous_avg - recent_avg  # ì–‘ìˆ˜ë©´ ê°œì„ 

        # 4ï¸âƒ£ ìµœê·¼ ë© ìƒì„¸ ì •ë³´ (ìµœëŒ€ 5ê°œ)
        recent_laps_detailed = []
        for lap in recent_laps.data[:5]:
            lap_id = lap["id"]
            try:
                # ì„¹í„° ë¶„ì„
                lap_data = fetch_lap_meta_and_data(lap_id)
                if lap_data:
                    controls_df = pd.DataFrame(lap_data["controls"])
                    controls_df.columns = [c.strip().lower() for c in controls_df.columns]
                    sector_results = get_sector_summary_by_lap_id(supabase, lap_id, controls_df)
                    
                    recent_laps_detailed.append({
                        "lap_id": lap_id,
                        "track": lap["track"],
                        "car": lap["car"],
                        "lap_time": lap["lap_time"],
                        "created_at": lap["created_at"],
                        "weather": lap.get("weather"),
                        "air_temp": lap.get("air_temp"),
                        "track_temp": lap.get("track_temp"),
                        "sector_count": len(sector_results),
                        "sectors": sector_results[:3]  # ì²˜ìŒ 3ê°œ ì„¹í„°ë§Œ
                    })
            except Exception as e:
                print(f"âŒ ë© {lap_id} ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                continue

        # 5ï¸âƒ£ íŠ¸ë™ë³„ ë¦¬ë”ë³´ë“œ (ê°™ì€ íŠ¸ë™ì˜ ìµœê³  ê¸°ë¡ë“¤)
        track_leaderboard = []
        if track:
            leaderboard_query = supabase.table("lap_meta").select("user_id, lap_time, car, created_at").eq("track", track.lower()).not_.is_("lap_time", "null").order("lap_time", desc=False).limit(10).execute()
            track_leaderboard = leaderboard_query.data or []

        return sanitize_for_json({
            "user_id": user_id,
            "track": track,
            "period_days": days,
            "total_laps": len(recent_laps.data),
            "summary": {
                "best_lap_time": round(best_lap_time, 3) if best_lap_time else None,
                "average_lap_time": round(avg_lap_time, 3) if avg_lap_time else None,
                "improvement_trend": round(improvement_trend, 3) if improvement_trend else None,
                "total_distance": sum([lap.get("lap_time", 0) * 100 for lap in recent_laps.data])  # ëŒ€ëµì  ê±°ë¦¬
            },
            "recent_laps": recent_laps_detailed,
            "performance_metrics": {
                "consistency_score": _calculate_consistency_score(lap_times),
                "improvement_rate": _calculate_improvement_rate(lap_times),
                "best_sector_times": _get_best_sector_times(user_id, track, days)
            },
            "track_leaderboard": track_leaderboard
        })

    except Exception as e:
        print(f"âŒ ëŒ€ì‹œë³´ë“œ ê°œìš” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@router.get("/dashboard/lap-detail/{lap_id}")
async def get_lap_dashboard_detail(lap_id: str):
    """
    íŠ¹ì • ë©ì˜ ëŒ€ì‹œë³´ë“œìš© ìƒì„¸ ë¶„ì„
    - ë¸Œë ˆì´í‚¹ ë¶„ì„ ìš”ì•½
    - ì½”ë„ˆë³„ ì„±ëŠ¥
    - ì‹œê°í™” ë°ì´í„°
    """
    try:
        # 1ï¸âƒ£ ë© ê¸°ë³¸ ì •ë³´
        lap_data = fetch_lap_meta_and_data(lap_id)
        if not lap_data:
            raise HTTPException(status_code=404, detail="ë© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        controls = lap_data["controls"]
        vehicle = lap_data["vehicle"]
        meta = lap_data["meta"]

        # 2ï¸âƒ£ DataFrame ì¤€ë¹„
        df_controls = pd.DataFrame(controls)
        df_vehicle = pd.DataFrame(vehicle)
        df_controls.columns = [c.strip().lower() for c in df_controls.columns]
        df_vehicle.columns = [c.strip().lower() for c in df_vehicle.columns]
        df = pd.merge(df_controls, df_vehicle, on="time", how="inner")

        # 3ï¸âƒ£ ì„¹í„° ë¶„ì„
        sector_results = get_sector_summary_by_lap_id(supabase, lap_id, df_controls)

        # 4ï¸âƒ£ ë¸Œë ˆì´í‚¹ ë¶„ì„
        track_name = meta.get("track", "").lower()
        segments = get_corner_segments_for_track(supabase, track_name)
        brake_results = analyze_braking_dynamics(df, segments)
        
        # 5ï¸âƒ£ í•µì‹¬ ì§€í‘œ ê³„ì‚°
        performance_metrics = _calculate_lap_performance_metrics(df, brake_results, sector_results)

        # 6ï¸âƒ£ ì‹œê°í™”ìš© ë°ì´í„° ì¤€ë¹„
        visualization_data = _prepare_visualization_data(df, brake_results, sector_results)

        return sanitize_for_json({
            "lap_id": lap_id,
            "meta": meta,
            "performance_metrics": performance_metrics,
            "sector_analysis": sector_results,
            "braking_analysis": {
                "segments": brake_results.get("segments", []),
                "summary": brake_results.get("summary", {})
            },
            "visualization_data": visualization_data,
            "insights": _generate_lap_insights(performance_metrics, brake_results, sector_results)
        })

    except Exception as e:
        print(f"âŒ ë© ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë© ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.get("/dashboard/performance-trends/{user_id}")
async def get_performance_trends(
    user_id: str,
    track: Optional[str] = Query(None),
    days: int = Query(30)
):
    """
    ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
    - ì‹œê°„ë³„ ë© íƒ€ì„ ë³€í™”
    - ì„¹í„°ë³„ ê°œì„  ì¶”ì´
    - ë¸Œë ˆì´í‚¹ íš¨ìœ¨ì„± ë³€í™”
    """
    try:
        date_filter = datetime.now() - timedelta(days=days)
        
        query = supabase.table("lap_meta").select("*").eq("user_id", user_id)
        if track:
            query = query.eq("track", track.lower())
        
        laps = query.gte("created_at", date_filter.isoformat()).order("created_at", desc=False).execute()
        
        if not laps.data:
            return {"trends": [], "insights": []}

        # íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±
        trends = []
        for lap in laps.data:
            if lap["lap_time"]:
                trends.append({
                    "date": lap["created_at"][:10],  # YYYY-MM-DD
                    "lap_time": lap["lap_time"],
                    "track": lap["track"],
                    "car": lap["car"]
                })

        return sanitize_for_json({
            "user_id": user_id,
            "track": track,
            "period_days": days,
            "trends": trends,
            "insights": _analyze_performance_trends(trends)
        })

    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

# ğŸ”§ í—¬í¼ í•¨ìˆ˜ë“¤

def _calculate_consistency_score(lap_times: List[float]) -> float:
    """ë© íƒ€ì„ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° (0-100)"""
    if len(lap_times) < 2:
        return 0.0
    
    mean_time = sum(lap_times) / len(lap_times)
    variance = sum((t - mean_time) ** 2 for t in lap_times) / len(lap_times)
    std_dev = variance ** 0.5
    
    # í‘œì¤€í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ (ìµœëŒ€ 100ì )
    consistency = max(0, 100 - (std_dev / mean_time * 100))
    return round(consistency, 1)

def _calculate_improvement_rate(lap_times: List[float]) -> float:
    """ê°œì„ ìœ¨ ê³„ì‚° (ìµœê·¼ vs ì´ˆê¸°)"""
    if len(lap_times) < 4:
        return 0.0
    
    recent_avg = sum(lap_times[:len(lap_times)//2]) / (len(lap_times)//2)
    early_avg = sum(lap_times[len(lap_times)//2:]) / (len(lap_times) - len(lap_times)//2)
    
    improvement = (early_avg - recent_avg) / early_avg * 100
    return round(improvement, 1)

def _get_best_sector_times(user_id: str, track: Optional[str], days: int) -> List[Dict]:
    """ìµœê³  ì„¹í„° íƒ€ì„ ì¡°íšŒ"""
    try:
        date_filter = datetime.now() - timedelta(days=days)
        
        # ì„¹í„° ê²°ê³¼ì—ì„œ ìµœê³  ê¸°ë¡ë“¤ ì¡°íšŒ
        query = supabase.table("sector_results").select("sector_index, sector_time, lap_id")
        query = query.eq("user_id", user_id)
        if track:
            query = query.eq("track", track.lower())
        
        sectors = query.gte("created_at", date_filter.isoformat()).execute()
        
        if not sectors.data:
            return []
        
        # ì„¹í„°ë³„ ìµœê³  ê¸°ë¡ ì°¾ê¸°
        best_sectors = {}
        for sector in sectors.data:
            sector_idx = sector["sector_index"]
            if sector_idx not in best_sectors or sector["sector_time"] < best_sectors[sector_idx]["sector_time"]:
                best_sectors[sector_idx] = sector
        
        return list(best_sectors.values())
    
    except Exception as e:
        print(f"âŒ ìµœê³  ì„¹í„° íƒ€ì„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def _calculate_lap_performance_metrics(df: pd.DataFrame, brake_results: Dict, sector_results: List[Dict]) -> Dict:
    """ë© ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
    try:
        # ê¸°ë³¸ ì§€í‘œ
        total_time = df["time"].iloc[-1] - df["time"].iloc[0]
        avg_speed = df["speed"].mean()
        max_speed = df["speed"].max()
        
        # ë¸Œë ˆì´í‚¹ ì§€í‘œ
        brake_segments = brake_results.get("segments", [])
        total_brake_time = sum(seg.get("duration", 0) for seg in brake_segments)
        brake_efficiency = (total_brake_time / total_time * 100) if total_time > 0 else 0
        
        # ì„¹í„° ì§€í‘œ
        sector_times = [s["best_time"] for s in sector_results if "best_time" in s]
        avg_sector_time = sum(sector_times) / len(sector_times) if sector_times else 0
        
        return {
            "total_time": round(total_time, 3),
            "average_speed": round(avg_speed, 1),
            "max_speed": round(max_speed, 1),
            "brake_efficiency": round(brake_efficiency, 1),
            "sector_count": len(sector_results),
            "avg_sector_time": round(avg_sector_time, 3),
            "brake_segments_count": len(brake_segments)
        }
    
    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return {}

def _prepare_visualization_data(df: pd.DataFrame, brake_results: Dict, sector_results: List[Dict]) -> Dict:
    """ì‹œê°í™”ìš© ë°ì´í„° ì¤€ë¹„"""
    try:
        # ê¸°ë³¸ ê·¸ë˜í”„ ë°ì´í„°
        graph_keys = [
            "time", "distance", "speed", "throttle", "brake", "steerangle", "gear",
            "g_lon", "g_lat", "abs"
        ]
        available_keys = [k for k in graph_keys if k in df.columns]
        graph_data = df[available_keys].to_dict(orient="records")
        
        # ë¸Œë ˆì´í‚¹ êµ¬ê°„ ë§ˆí‚¹
        brake_segments = brake_results.get("segments", [])
        for segment in brake_segments:
            start_time = segment.get("start_time")
            end_time = segment.get("end_time")
            if start_time and end_time:
                # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ë°ì´í„°ì— ë¸Œë ˆì´í‚¹ ë§ˆí¬ ì¶”ê°€
                for data_point in graph_data:
                    if start_time <= data_point.get("time", 0) <= end_time:
                        data_point["is_braking"] = True
        
        return {
            "graph_data": graph_data,
            "brake_segments": brake_segments,
            "sector_markers": sector_results
        }
    
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        return {"graph_data": [], "brake_segments": [], "sector_markers": []}

def _generate_lap_insights(metrics: Dict, brake_results: Dict, sector_results: List[Dict]) -> List[str]:
    """ë© ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []
    
    try:
        # ë¸Œë ˆì´í‚¹ ì¸ì‚¬ì´íŠ¸
        brake_segments = brake_results.get("segments", [])
        if brake_segments:
            avg_brake_peak = sum(seg.get("brake_peak", 0) for seg in brake_segments) / len(brake_segments)
            if avg_brake_peak > 80:
                insights.append("ë¸Œë ˆì´í‚¹ ê°•ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ë” ë¶€ë“œëŸ¬ìš´ ë¸Œë ˆì´í‚¹ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
            elif avg_brake_peak < 50:
                insights.append("ë¸Œë ˆì´í‚¹ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” í™•ì‹¤í•œ ì œë™ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
        
        # ì†ë„ ì¸ì‚¬ì´íŠ¸
        if metrics.get("max_speed", 0) > 200:
            insights.append("ê³ ì† êµ¬ê°„ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.")
        
        # ì¼ê´€ì„± ì¸ì‚¬ì´íŠ¸
        if metrics.get("brake_efficiency", 0) > 30:
            insights.append("ë¸Œë ˆì´í‚¹ ì‹œê°„ì´ ì „ì²´ ë©ì˜ 30% ì´ìƒì…ë‹ˆë‹¤. ë” íš¨ìœ¨ì ì¸ ë¼ì¸ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        if not insights:
            insights.append("ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ì£¼í–‰ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"âŒ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        insights = ["ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."]
    
    return insights

def _analyze_performance_trends(trends: List[Dict]) -> List[str]:
    """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
    insights = []
    
    try:
        if len(trends) < 3:
            return ["ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."]
        
        # ìµœê·¼ 3ê°œ vs ì´ì „ 3ê°œ ë¹„êµ
        recent_3 = [t["lap_time"] for t in trends[-3:]]
        previous_3 = [t["lap_time"] for t in trends[-6:-3]] if len(trends) >= 6 else []
        
        if previous_3:
            recent_avg = sum(recent_3) / len(recent_3)
            previous_avg = sum(previous_3) / len(previous_3)
            improvement = previous_avg - recent_avg
            
            if improvement > 0.5:
                insights.append(f"ìµœê·¼ {improvement:.1f}ì´ˆ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
            elif improvement < -0.5:
                insights.append("ìµœê·¼ ì„±ëŠ¥ì´ ë‹¤ì†Œ í•˜ë½í–ˆìŠµë‹ˆë‹¤. ì»¨ë””ì…˜ì„ ì ê²€í•´ë³´ì„¸ìš”.")
            else:
                insights.append("ì„±ëŠ¥ì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ì¼ê´€ì„± ë¶„ì„
        all_times = [t["lap_time"] for t in trends]
        if len(all_times) > 5:
            std_dev = (sum((t - sum(all_times)/len(all_times))**2 for t in all_times) / len(all_times))**0.5
            if std_dev < 1.0:
                insights.append("ë§¤ìš° ì¼ê´€ëœ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
            elif std_dev > 3.0:
                insights.append("ì„±ëŠ¥ í¸ì°¨ê°€ í½ë‹ˆë‹¤. ë” ì•ˆì •ì ì¸ ì£¼í–‰ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.")
    
    except Exception as e:
        print(f"âŒ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        insights = ["íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    return insights
